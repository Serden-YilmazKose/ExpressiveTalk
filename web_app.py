import os
import sys
from pathlib import Path
import streamlit as st

# V√©rifier si mediapipe est disponible
try:
    import mediapipe
    MEDIAPIPE_AVAILABLE = True
except ImportError:
    MEDIAPIPE_AVAILABLE = False

# V√©rifier si PyTorch est disponible
try:
    import torch
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False
    st.error("‚ö†Ô∏è PyTorch n'est pas install√©. L'application ne peut pas fonctionner.")
    st.stop()

from integration_withWEB import main_video_gen

# --- Configuration ---
UPLOAD_FOLDER = "Uploaded_files"
VIDEO_FOLDER = "Output_video"
CHECKPOINT_PATH = "checkpoints/wav2lip_gan.pth"

# Cr√©er les dossiers n√©cessaires
for folder in [UPLOAD_FOLDER, VIDEO_FOLDER, "temp", "checkpoints"]:
    os.makedirs(folder, exist_ok=True)

# --- Header ---
st.title("üé¨ ExpressiveTalk")
st.markdown("*Synchronisation labiale avec transfert d'√©motion*")

# --- V√©rification des mod√®les ---
with st.sidebar:
    st.header("üìä √âtat du syst√®me")
    
    # Python version
    st.text(f"üêç Python: {sys.version.split()[0]}")
    
    # MediaPipe
    if MEDIAPIPE_AVAILABLE:
        st.success("‚úÖ MediaPipe disponible")
    else:
        st.warning("‚ö†Ô∏è MediaPipe indisponible")
        st.caption("Le transfert d'√©motion sera d√©sactiv√©")
    
    # PyTorch
    if TORCH_AVAILABLE:
        st.success("‚úÖ PyTorch disponible")
        device = "CUDA" if torch.cuda.is_available() else "CPU"
        st.caption(f"Device: {device}")
    
    # Mod√®le Wav2Lip
    if os.path.exists(CHECKPOINT_PATH):
        st.success("‚úÖ Mod√®le Wav2Lip charg√©")
        file_size = os.path.getsize(CHECKPOINT_PATH) / (1024 * 1024)
        st.caption(f"Taille: {file_size:.1f} MB")
    else:
        st.error("‚ùå Mod√®le Wav2Lip manquant")
        st.markdown("""
        **Instructions de t√©l√©chargement:**
        1. T√©l√©chargez le mod√®le depuis [GitHub](https://github.com/Rudrabha/Wav2Lip#getting-the-weights)
        2. Placez `wav2lip_gan.pth` dans le dossier `checkpoints/`
        3. Ou ex√©cutez: `python download_models.py`
        """)

# Afficher un avertissement global si mediapipe n'est pas disponible
if not MEDIAPIPE_AVAILABLE:
    st.info("""
    ‚ÑπÔ∏è **Mode de fonctionnement limit√©**
    
    Le transfert d'√©motion n√©cessite MediaPipe qui n'est pas disponible dans cet environnement.
    Seule la synchronisation labiale (lip-sync) fonctionnera.
    
    **Pour activer toutes les fonctionnalit√©s:**
    1. Cr√©ez un fichier `.python-version` avec `3.12`
    2. Poussez sur GitHub et red√©marrez l'application
    """)

# --- Mode Selection ---
st.header("‚öôÔ∏è Configuration")

if MEDIAPIPE_AVAILABLE:
    mode = st.radio(
        "Mode de traitement",
        options=["Lip-sync uniquement", "Lip-sync + √âmotion"],
        help="Choisissez d'ajouter ou non le transfert d'√©motion"
    )
    enable_emotion = mode == "Lip-sync + √âmotion"
else:
    st.info("üé§ Mode: Lip-sync uniquement")
    enable_emotion = False

# --- File Upload ---
st.header("üì§ Charger les fichiers")

col1, col2 = st.columns(2)

with col1:
    video_file = st.file_uploader(
        "Vid√©o du visage",
        type=["mp4", "mov", "avi"],
        help="Vid√©o contenant le visage √† animer"
    )
    if video_file:
        st.video(video_file)

with col2:
    audio_file = st.file_uploader(
        "Fichier audio",
        type=["mp3", "wav", "ogg"],
        help="Audio pour la synchronisation labiale"
    )
    if audio_file:
        st.audio(audio_file)

# --- Emotion Settings ---
emotion_to_use = None
intensity_value = 0.0

if enable_emotion:
    st.header("üòä Param√®tres d'√©motion")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        emotion_options = ["Neutral", "Happy", "Sad", "Fear", "Anger", "Surprise", "Disgust"]
        selected_emotion = st.selectbox(
            "√âmotion",
            emotion_options,
            help="Choisissez l'√©motion √† appliquer"
        )
    
    with col2:
        intensity_value = st.slider(
            "Intensit√©",
            min_value=0.0,
            max_value=1.0,
            value=0.6,
            step=0.05,
            help="Force de l'√©motion (0 = aucune, 1 = maximum)"
        )
    
    # Mapper les √©motions
    emotion_mapping = {
        "Neutral": "neutral",
        "Happy": "happy",
        "Sad": "sad",
        "Fear": "fearful",
        "Anger": "angry",
        "Surprise": "surprised",
        "Disgust": "disgusted"
    }
    
    if intensity_value > 0:
        emotion_to_use = emotion_mapping[selected_emotion]
    
    # Afficher un aper√ßu
    st.caption(f"‚ú® √âmotion s√©lectionn√©e: **{selected_emotion}** ({intensity_value:.0%})")

# --- Process Button ---
st.header("üé¨ G√©n√©ration")

# V√©rifier que tout est pr√™t
can_process = True
error_messages = []

if not video_file:
    error_messages.append("üìπ Veuillez charger une vid√©o")
    can_process = False

if not audio_file:
    error_messages.append("üéµ Veuillez charger un fichier audio")
    can_process = False

if not os.path.exists(CHECKPOINT_PATH):
    error_messages.append("ü§ñ Le mod√®le Wav2Lip est manquant")
    can_process = False

if error_messages:
    for msg in error_messages:
        st.warning(msg)

# Bouton de traitement
if st.button("üöÄ G√©n√©rer la vid√©o", disabled=not can_process, type="primary"):
    try:
        # Sauvegarder les fichiers upload√©s
        video_path = Path(UPLOAD_FOLDER) / video_file.name
        audio_path = Path(UPLOAD_FOLDER) / audio_file.name
        
        with st.status("üíæ Sauvegarde des fichiers...", expanded=True) as status:
            with open(video_path, "wb") as f:
                f.write(video_file.getbuffer())
            st.write(f"‚úì Vid√©o sauvegard√©e: `{video_path.name}`")
            
            with open(audio_path, "wb") as f:
                f.write(audio_file.getbuffer())
            st.write(f"‚úì Audio sauvegard√©: `{audio_path.name}`")
            
            status.update(label="‚úÖ Fichiers sauvegard√©s", state="complete")
        
        # Afficher les param√®tres
        with st.expander("üìã Param√®tres de g√©n√©ration", expanded=False):
            st.json({
                "Vid√©o": str(video_path),
                "Audio": str(audio_path),
                "√âmotion": emotion_to_use or "Aucune",
                "Intensit√©": f"{intensity_value:.2f}",
                "Device": "CUDA" if torch.cuda.is_available() else "CPU"
            })
        
        # G√©n√©rer la vid√©o
        output_file_path = Path(VIDEO_FOLDER) / f"result_{video_file.name}"
        
        with st.spinner("üé• G√©n√©ration de la vid√©o en cours... Cela peut prendre plusieurs minutes."):
            progress_bar = st.progress(0, text="Initialisation...")
            
            # Appeler la fonction de g√©n√©ration
            main_video_gen(
                checkpoint_path=CHECKPOINT_PATH,
                face=str(video_path),
                audio=str(audio_path),
                outfile=str(output_file_path),
                emotion=emotion_to_use,
                emotion_strength=intensity_value,
                emotion_fps=None
            )
            
            progress_bar.progress(100, text="Termin√©!")
        
        st.success("‚úÖ Vid√©o g√©n√©r√©e avec succ√®s!")
        
        # Afficher et t√©l√©charger la vid√©o
        if output_file_path.exists():
            st.header("üéûÔ∏è R√©sultat")
            
            col1, col2 = st.columns([3, 1])
            
            with col1:
                st.video(str(output_file_path))
            
            with col2:
                file_size = os.path.getsize(output_file_path) / (1024 * 1024)
                st.metric("Taille", f"{file_size:.1f} MB")
                
                with open(output_file_path, "rb") as f:
                    st.download_button(
                        label="‚¨áÔ∏è T√©l√©charger",
                        data=f.read(),
                        file_name=output_file_path.name,
                        mime="video/mp4",
                        use_container_width=True
                    )
        else:
            st.error("‚ö†Ô∏è Le fichier de sortie n'a pas √©t√© cr√©√©")
            
    except Exception as e:
        st.error(f"‚ùå Erreur lors de la g√©n√©ration: {str(e)}")
        with st.expander("üîç D√©tails de l'erreur"):
            st.exception(e)

# --- Footer ---
st.markdown("---")
st.caption("ExpressiveTalk - Synchronisation labiale avec transfert d'√©motion | Powered by Wav2Lip & MediaPipe")